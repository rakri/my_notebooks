{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rakri/.local/lib/python3.10/site-packages/pydantic/_internal/_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "* 'smart_union' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /home/rakri/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nall_embeddings = []\\nwith open('query_phrases.txt','r') as f:\\n    for line in f:\\n        texts = [line]\\n#        print(line)\\n        response = co.embed(\\n        model='embed-english-light-v3.0',\\n        texts=texts,\\n        input_type='search_query',  # or 'search_query', 'search_document' depending on your use case\\n        embedding_types=['float']  # or 'int8', 'binary' for different compression levels\\n        )\\n        all_embeddings.extend(response.embeddings.float)\\n        time.sleep(0.1)\\n\\n    numpy_array = np.array(all_embeddings)\\n    print(numpy_array.shape)\\n    np.save('query_vectors.npy', numpy_array)\\n\\n\\n\\n#response = co.embed(\\n#    model='embed-english-light-v3.0',\\n#    texts=texts,\\n#    input_type='search_document',  # or 'search_query', 'search_document' depending on your use case\\n#    embedding_types=['float']  # or 'int8', 'binary' for different compression levels\\n#)\\n\\n#embeddings = response.embeddings\\n#print(response.texts)\\n#print(len(response.embeddings.float))\\n\\n\\n\\n# Example list of lists\\n\\n\\n# Convert to NumPy array\\nnumpy_array = np.array(response.embeddings.float)\\n\\nprint(numpy_array.shape)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import cohere\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import numpy as np\n",
    "import transformers\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"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\")\n",
    "\n",
    "\n",
    "# Replace 'YOUR_API_KEY' with your actual API key\n",
    "#co = cohere.Client('w2OtjQZqgQ7cRif50YXixEtxyXXBmO5oNC3pBhcH')\n",
    "co = cohere.Client('nvccZvrHbWcMNHw399CwnLkmi9ddXFCNnzc6dBie')\n",
    "\n",
    "\n",
    "texts = [\n",
    "    'Hello from Cohere!',\n",
    "    'Hello from Cohere!',\n",
    "    'Hello from Cohere!',\n",
    "    'Hello from Cohere!',\n",
    "]\n",
    "\n",
    "'''\n",
    "all_embeddings = []\n",
    "with open('query_phrases.txt','r') as f:\n",
    "    for line in f:\n",
    "        texts = [line]\n",
    "#        print(line)\n",
    "        response = co.embed(\n",
    "        model='embed-english-light-v3.0',\n",
    "        texts=texts,\n",
    "        input_type='search_query',  # or 'search_query', 'search_document' depending on your use case\n",
    "        embedding_types=['float']  # or 'int8', 'binary' for different compression levels\n",
    "        )\n",
    "        all_embeddings.extend(response.embeddings.float)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    numpy_array = np.array(all_embeddings)\n",
    "    print(numpy_array.shape)\n",
    "    np.save('query_vectors.npy', numpy_array)\n",
    "\n",
    "\n",
    "\n",
    "#response = co.embed(\n",
    "#    model='embed-english-light-v3.0',\n",
    "#    texts=texts,\n",
    "#    input_type='search_document',  # or 'search_query', 'search_document' depending on your use case\n",
    "#    embedding_types=['float']  # or 'int8', 'binary' for different compression levels\n",
    "#)\n",
    "\n",
    "#embeddings = response.embeddings\n",
    "#print(response.texts)\n",
    "#print(len(response.embeddings.float))\n",
    "\n",
    "\n",
    "\n",
    "# Example list of lists\n",
    "\n",
    "\n",
    "# Convert to NumPy array\n",
    "numpy_array = np.array(response.embeddings.float)\n",
    "\n",
    "print(numpy_array.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['main_category', 'title', 'average_rating', 'rating_number', 'features', 'description', 'price', 'images', 'videos', 'store', 'categories', 'details', 'parent_asin', 'bought_together', 'subtitle', 'author'])\n",
      "['Package Dimension : 57.19 \" L x 23.05 \" W x 8.16 \" H', 'Country of Origin: UNITED STATES', 'Model Number : 84192', 'Item Package Weight : 13.07 pounds']\n",
      "3\n",
      "(192, 384)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_meta_Automotive\", split=\"full\")\n",
    "\n",
    "print(dataset[0].keys())\n",
    "print(dataset[1000][\"features\"])\n",
    "# Function to process batches\n",
    "def process_batches(dataset, batch_size=96):\n",
    "#    for i in range(0, len(dataset), batch_size):\n",
    "    all_embeddings = []\n",
    "    for i in range(0, 192, batch_size):\n",
    "        batch = dataset[i:i + batch_size]\n",
    "        texts = [title+\" \"+' '.join(map(str, desc)) for (title, desc) in zip(batch['title'], batch['description'])]\n",
    "        response = co.embed(\n",
    "            model='embed-english-light-v3.0',\n",
    "            texts=texts,\n",
    "            input_type='search_document',  # or 'search_query', 'search_document' depending on your use case\n",
    "            embedding_types=['float']  # or 'int8', 'binary' for different compression levels\n",
    "        )\n",
    "        all_embeddings.extend(response.embeddings.float)\n",
    "\n",
    "    numpy_array = np.array(all_embeddings)\n",
    "    print(numpy_array.shape)\n",
    "# Example usage\n",
    "\n",
    "md = dataset[3:6]\n",
    "print(len(md[\"title\"]))\n",
    "process_batches(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trim\n",
      "['Automotive', 'Exterior Accessories', 'Bumper Stickers, Decals & Magnets', 'Decals']\n"
     ]
    }
   ],
   "source": [
    "size = len(dataset[100]['categories'])\n",
    "print(dataset[100]['categories'][int(size/2)])\n",
    "print(dataset[947804]['categories'])\n",
    "\n",
    "# Function to read the file and convert to list of dictionaries\n",
    "def convert_file_to_dict_list(file_path):\n",
    "    dict_list = []\n",
    "    idx =0\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split('\\t')\n",
    "            row_id = parts[0]\n",
    "            brand = parts[1]\n",
    "            #categories = parts[2].split(',')\n",
    "            categories = dataset[int(row_id)]['categories']\n",
    "            rating = parts[3]\n",
    "            price = parts[4]\n",
    "            dict_list.append({\n",
    "                'row_id': row_id,\n",
    "                'brand': brand,\n",
    "                'categories': categories,\n",
    "                'rating': rating\n",
    "            })\n",
    "            idx+=1\n",
    "            if (idx%1000 == 0):\n",
    "                print(\".\", end=\"\")\n",
    "        print(\"\\n\")\n",
    "    return dict_list\n",
    "\n",
    "\n",
    "def convert_query_to_dict_list(file_path):\n",
    "    dict_list = []\n",
    "    idx =0\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split('\\t')\n",
    "            q_id = parts[0]\n",
    "            categories = dataset[int(q_id)]['categories']\n",
    "            text = parts[1]\n",
    "            brands = parts[2].split(',')\n",
    "            rating = parts[3]\n",
    "            price = parts[4]\n",
    "            dict_list.append({\n",
    "                'query_id': q_id,\n",
    "                'brands': brands,\n",
    "                'rating': rating,\n",
    "                'categories': categories\n",
    "            })\n",
    "            idx+=1\n",
    "            if (idx%1000 == 0):\n",
    "                print(\".\", end=\"\")\n",
    "        print(\"\\n\")\n",
    "    return dict_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "\n",
      "{'row_id': '0', 'brand': 'Caltric', 'categories': ['Automotive', 'Motorcycle & Powersports', 'Parts', 'Filters', 'Oil Filters'], 'rating': '5'}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "file_path = '/home/rakri/amazon_automotive_dataset_cohere/base_labels.txt'\n",
    "base_labels = convert_file_to_dict_list(file_path)\n",
    "print(base_labels[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_path = '/home/rakri/amazon_automotive_dataset_cohere/query_labels.txt'\n",
    "query_labels = convert_query_to_dict_list(query_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'row_id': '999999', 'brand': 'Draw-Tite', 'categories': ['Automotive', 'Exterior Accessories', 'Towing Products & Winches', 'Hitches', 'Receivers'], 'rating': '4'}\n",
      "{'query_id': '947804', 'brands': ['AK Wall Art', 'Vool', 'EOI', 'RAINVIN', 'Honch'], 'rating': '5', 'categories': ['Automotive', 'Exterior Accessories', 'Bumper Stickers, Decals & Magnets', 'Decals']}\n"
     ]
    }
   ],
   "source": [
    "print(base_labels[999999])\n",
    "print(query_labels[0])\n",
    "\n",
    "def count_satisfying_elements_brand(base_dicts, query_dict):\n",
    "    query_brands = set(query_dict[\"brands\"])\n",
    "    #print(query_brands)\n",
    "    count = 0\n",
    "    for entry in base_dicts:\n",
    "        #print(entry)\n",
    "        base_brands = set([entry[\"brand\"]])\n",
    "#        print(base_brands)\n",
    "        if query_brands & base_brands:  # Check for intersection\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def count_satisfying_elements_cats(base_dicts, query_dict):\n",
    "    num_cats = len(query_dict[\"categories\"])\n",
    "    #print(query_dict[\"categories\"])\n",
    "    #print(query_dict[\"categories\"][1])\n",
    "    query_cats = set([query_dict[\"categories\"][1]])\n",
    "    #print(query_cats)\n",
    "    #print(query_brands)\n",
    "    count = 0\n",
    "    for entry in base_dicts:\n",
    "        #print(entry)\n",
    "        base_cats = set(entry[\"categories\"])\n",
    "#        if (entry[\"row_id\"]==57334):\n",
    "        #print(base_cats)\n",
    "        #print(base_cats)\n",
    "#        print(base_brands)\n",
    "        if query_cats & base_cats:  # Check for intersection\n",
    "            count += 1\n",
    "    return count    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query_id': '947804', 'brands': ['AK Wall Art', 'Vool', 'EOI', 'RAINVIN', 'Honch'], 'rating': '5', 'categories': ['Automotive', 'Exterior Accessories', 'Bumper Stickers, Decals & Magnets', 'Decals']}\n"
     ]
    }
   ],
   "source": [
    "print(query_labels[0])\n",
    "#print(count_satisfying_elements_cats(base_labels[57330:57340], query_labels[0]))\n",
    "\n",
    "matching_counts_category = [count_satisfying_elements_cats(base_labels, query) for query in query_labels]\n",
    "\n",
    "# Calculate percentiles\n",
    "cat_percentiles = np.percentile(matching_counts_category, [1, 2, 3, 4, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 95])\n",
    "\n",
    "#print (percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9304.    13836.    19300.    23616.    41721.75  64849.   186984.\n",
      " 253856.   266911.   266911.   851996.   851996.   851996.   851996.\n",
      " 851996.  ]\n",
      "1190 384\n",
      "[[ 5.9967041e-03  3.1311035e-02 -1.6479492e-02 ... -3.6529541e-02\n",
      "   1.3122559e-02  2.5741577e-02]\n",
      " [ 2.9582977e-03  1.2397766e-02 -7.2300434e-05 ...  6.9580078e-02\n",
      "   9.0742111e-04 -1.5174866e-02]\n",
      " [ 2.3971558e-02 -3.7872314e-02  7.7819824e-02 ...  7.2753906e-02\n",
      "  -1.1645508e-01  5.9265137e-02]\n",
      " ...\n",
      " [-5.4565430e-02  1.9638062e-02 -3.1463623e-02 ... -2.7374268e-02\n",
      "  -3.2867432e-02  6.0699463e-02]\n",
      " [-2.6443481e-02  3.7872314e-02  7.2204590e-02 ...  5.3436279e-02\n",
      "   1.8424988e-03  6.8054199e-02]\n",
      " [ 2.1347046e-02 -8.0566406e-03  6.1889648e-02 ... -3.3630371e-02\n",
      "  -8.7097168e-02 -2.0568848e-02]]\n",
      "(0, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7119, 384)\n",
      "Data has been written to /home/rakri/new_query_labels_amazon.txt\n"
     ]
    }
   ],
   "source": [
    "print(cat_percentiles)\n",
    "\n",
    "import numpy as np\n",
    "import struct\n",
    "\n",
    "# Function to load the binary matrix\n",
    "def load_binary_matrix(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        # Read the number of rows (first 4 bytes)\n",
    "        nr = struct.unpack('i', f.read(4))\n",
    "        \n",
    "        # Read the dimension d (next 4 bytes)\n",
    "        dimm = struct.unpack('i', f.read(4))\n",
    "        \n",
    "        print(nr[0],dimm[0])\n",
    "        # Read the remaining bytes for the matrix data\n",
    "        matrix_data = np.fromfile(f, dtype=np.float32)\n",
    "        \n",
    "        # Reshape the data into the matrix with shape (num_rows, dim)\n",
    "        matrix = matrix_data.reshape((nr[0], dimm[0]))\n",
    "        \n",
    "    return matrix\n",
    "\n",
    "# Example usage\n",
    "file_path = \"/home/rakri/amazon_automotive_dataset_cohere/amazon_query.bin\"\n",
    "matrix = load_binary_matrix(file_path)\n",
    "print(matrix)\n",
    "\n",
    "final_query = np.empty((0, 384))\n",
    "print(final_query.shape)\n",
    "\n",
    "output_query_file = \"/home/rakri/new_query_labels_amazon.txt\"\n",
    "# Open the file in write mode\n",
    "with open(output_query_file, \"w\") as file:\n",
    "    idx = 0\n",
    "#    file.write(\"\\t\".join(query_labels[0].keys()) + \"\\n\")\n",
    "    for data in query_labels:\n",
    "    # Write the header\n",
    "        file.write(\"CAT=\"+data[\"categories\"][1].replace(\" \", \"\").replace(\"&\",\"\").replace(\",\",\"\") + \"\\n\")\n",
    "        final_query = np.vstack([final_query, matrix[idx]])\n",
    "        file.write(\"CAT=\"+data[\"categories\"][1].replace(\" \", \"\").replace(\"&\",\"\").replace(\",\",\"\") + \"&&RATING=4||RATING=5\" + \"\\n\")\n",
    "        final_query = np.vstack([final_query, matrix[idx]])\n",
    "        file.write(\"CAT=\"+data[\"categories\"][1].replace(\" \", \"\").replace(\"&\",\"\").replace(\",\",\"\") + \"&&RATING=5\" + \"\\n\")\n",
    "        final_query = np.vstack([final_query, matrix[idx]])\n",
    "        if(len(data[\"categories\"])>=3):\n",
    "            file.write(\"CAT=\"+data[\"categories\"][2].replace(\" \", \"\").replace(\"&\",\"\").replace(\",\",\"\") + \"\\n\")\n",
    "            final_query = np.vstack([final_query, matrix[idx]])\n",
    "            file.write(\"CAT=\"+data[\"categories\"][2].replace(\" \", \"\").replace(\"&\",\"\").replace(\",\",\"\") + \"&&RATING=4||RATING=5\" + \"\\n\")\n",
    "            final_query = np.vstack([final_query, matrix[idx]])\n",
    "            file.write(\"CAT=\"+data[\"categories\"][2].replace(\" \", \"\").replace(\"&\",\"\").replace(\",\",\"\") + \"&&RATING=5\" + \"\\n\")\n",
    "            final_query = np.vstack([final_query, matrix[idx]])            \n",
    "\n",
    "print (final_query.shape)\n",
    "print(f\"Data has been written to {output_query_file}\")\n",
    "\n",
    "def write_array_to_binary_file(array, file_path):\n",
    "    # Get the number of rows and columns\n",
    "    num_rows, num_cols = array.shape\n",
    "    \n",
    "    with open(file_path, \"wb\") as f:\n",
    "        # Write the number of rows (4 bytes)\n",
    "        f.write(struct.pack('i', num_rows))\n",
    "        \n",
    "        # Write the number of columns (4 bytes)\n",
    "        f.write(struct.pack('i', num_cols))\n",
    "        \n",
    "        # Write the array data (4*n*d bytes)\n",
    "        f.write(array.astype(np.float32).tobytes())\n",
    "\n",
    "# Example usage\n",
    "array = np.array([[1.1, 2.2, 3.3], [4.4, 5.5, 6.6]], dtype=np.float32)\n",
    "file_path = \"/home/rakri/test.bin\"\n",
    "write_array_to_binary_file(array, file_path)\n",
    "file_path = \"/home/rakri/new_amazon_query.bin\"\n",
    "write_array_to_binary_file(final_query, file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_base_labels = \"/home/rakri/new_base_labels_amazon.txt\"\n",
    "with open(output_base_labels, \"w\") as file:\n",
    "    idx = 0\n",
    "#    file.write(\"\\t\".join(query_labels[0].keys()) + \"\\n\")\n",
    "    for data in base_labels:\n",
    "    # Write the header\n",
    "        file.write(\"BRAND=\"+data[\"brand\"].replace(\" \", \"\").replace(\"&\",\"\").replace(\",\",\"\"))\n",
    "        for cat in data[\"categories\"]:\n",
    "                file.write(\",CAT=\"+cat.replace(\" \", \"\").replace(\"&\",\"\").replace(\",\",\"\"))\n",
    "        file.write(\",RATING=\"+data[\"rating\"].replace(\" \", \"\").replace(\"&\",\"\").replace(\",\",\"\"))\n",
    "        file.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motorcycle & Powersports , 264494\n",
      "Tires & Wheels , 64849\n",
      "Interior Accessories , 186984\n",
      "Replacement Parts , 851996\n",
      "Car Care , 23616\n",
      "Tools & Equipment , 60090\n",
      "Exterior Accessories , 253856\n",
      "Oils & Fluids , 10626\n",
      "Lights & Lighting Accessories , 128298\n",
      "RV Parts & Accessories , 19300\n",
      "Paint & Paint Supplies , 13836\n",
      "Performance Parts & Accessories , 9304\n",
      "EV Care , 15\n",
      "Parts , 2417\n",
      "Automotive Enthusiast Merchandise , 1486\n",
      "Heavy Duty & Commercial Vehicle Equipment , 4405\n",
      "Heavy Duty & Commercial Vehicles Parts , 359\n",
      "Truck Parts & Accessories , 246\n",
      "RV_Upgrade , 537\n",
      "Jeep Parts & Accessories , 113\n",
      "V4 Customers Keep It - 50% , 7\n",
      "Automotive Original Equipment Manufacturer (OEM) Parts , 139\n",
      "Tires Ship to Store , 47\n",
      "N-Fab Truck & SUV Step Systems , 3\n",
      "Automotive Outlet , 62\n",
      "Summer Savings Event , 14\n",
      "ACDelco Professional Brake Pads , 1\n",
      "Save on Camco RV & Camping Accessories , 8\n",
      "Winter Driving , 5\n",
      "Electric Vehicle (EV) Storefront , 1\n",
      "Batteries Ship to Store , 2\n",
      "Automotive Low Return Rate Alert , 29\n",
      "Bosch , 1\n",
      "Rugged Ridge Deals , 10\n",
      "Car Electronics & Accessories , 11\n",
      "V4 Customers Keep It - 30% , 21\n",
      "ACDelco Professonal Steering , 2\n",
      "GM Genuine Parts & ACDelco , 25\n",
      "Truck Hero Jeep Drivetrain and Skid Plates , 2\n",
      "Heavy Duty Engine Parts , 5\n",
      "ACDelco Rotors , 11\n",
      "Lund - Truck Store , 9\n",
      "Home Charging Stations , 4\n",
      "EV Lifestyle , 11\n",
      "EV Learning Center , 5\n",
      "Camco Store , 2\n",
      "Lund Nerf Bars & Running Boards , 3\n",
      "3M Automotive Brand Store , 1\n",
      "EV deals , 4\n",
      "RV Winterization , 5\n",
      "Dorman Steering Shafts , 2\n",
      "Reese Towpower Accessories , 3\n",
      "Automotive accessories for kids - Ages&Stages , 5\n",
      "EV Chargers , 1\n",
      "Truck Season 2020 , 2\n",
      "Classic Accessories , 2\n",
      "RV_Maintenance , 6\n",
      "2019 Truck Season , 8\n",
      "Summer Savings Event 2019 , 7\n",
      "Truck Hero - Truxedo, Extang, BAK, BedRug, NFAB, Retrax, Undercover , 4\n",
      "ACDelco Electronics , 1\n",
      "Auto parts , 2\n",
      "Classic Accessories Auto , 2\n",
      "ACDelco EGR Valves , 1\n",
      "Subscribe & Save , 1\n",
      "V4 Customers Keep It - 70% , 1\n",
      "Trico Wiper Pair Packs , 1\n",
      "Reese Brands , 1\n",
      "ACDelco wires and cables , 1\n",
      "Monroe Max-Lift , 2\n",
      "Husy Liners and Gator Covers , 1\n",
      "ACDelco Save 20% , 1\n",
      "Frustration-Free Packaging: Automotive - US , 13\n",
      "Truck Hero Jeep Off-Road Performance , 1\n",
      "1897346\n"
     ]
    }
   ],
   "source": [
    "category_to_brand = {}\n",
    "brand_count = {}\n",
    "for row in base_labels:\n",
    "    brand = row[\"brand\"]\n",
    "    if brand not in brand_count:\n",
    "        brand_count[brand] = 0\n",
    "    brand_count[brand] += 1\n",
    "    if (len(row[\"categories\"]) < 2):\n",
    "        continue\n",
    "    cat = row[\"categories\"][1]\n",
    "    if cat not in category_to_brand:\n",
    "        category_to_brand[cat] = []\n",
    "        #print(cat)\n",
    "    category_to_brand[cat].append(brand)\n",
    "\n",
    "cumul = 0\n",
    "#print(len(category_to_brand[\"Exterior Accessories\"]))\n",
    "for cat in category_to_brand:\n",
    "    print(cat,\",\", len(category_to_brand[cat]))\n",
    "    cumul += len(category_to_brand[cat])\n",
    "print(cumul)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "Caltric 7978\n",
      "Dorman 24846\n",
      "24846 , 2003129\n",
      "NULL                       174821\n",
      "Dorman                      24846\n",
      "ACDelco                     20815\n",
      "Evan Fischer                10274\n",
      "Detroit Axle                 9189\n",
      "Honda                        8731\n",
      "WeatherTech                  8680\n",
      "A-Premium                    8436\n",
      "Caltric                      7978\n",
      "ECCPP                        7338\n",
      "Standard Motor Products      7105\n",
      "Power Stop                   6954\n",
      "TYC                          6780\n",
      "Generic                      6495\n",
      "Auto Dynasty                 6470\n",
      "Gates                        6456\n",
      "Beck/Arnley                  6249\n",
      "Mopar                        6248\n",
      "Garage-Pro                   6212\n",
      "Ford                         5974\n",
      "Raybestos                    5903\n",
      "MOOG                         5808\n",
      "SCITOO                       5608\n",
      "GM                           5543\n",
      "AM Autoparts                 5112\n",
      "Callahan BRAKE PARTS         5061\n",
      "Tuningpros                   5039\n",
      "Spectra Premium              5003\n",
      "Motorcraft                   4995\n",
      "AUTOANDART                   4798\n",
      "X AUTOHAUX                   4692\n",
      "Coverking                    4637\n",
      "Cardone                      4585\n",
      "General Motors               4578\n",
      "CafePress                    4509\n",
      "DEPO                         4494\n",
      "Monroe                       4253\n",
      "Centric                      4160\n",
      "Sherman                      3971\n",
      "Rareelectrical               3907\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"-----\")\n",
    "\n",
    "max_cnt = 0\n",
    "cumul_cnt = 0\n",
    "for brand in brand_count:\n",
    "    #print(brand, \",\", brand_count[brand])\n",
    "    if ((brand_count[brand] > max_cnt) & (brand != \"NULL\")):\n",
    "        max_cnt = brand_count[brand]\n",
    "        print(brand, brand_count[brand])\n",
    "    cumul_cnt += brand_count[brand]\n",
    "\n",
    "print(max_cnt, \",\", cumul_cnt)\n",
    "\n",
    "\n",
    "series = pd.Series(brand_count)\n",
    "\n",
    "sorted_series = series.sort_values(ascending=False)\n",
    "\n",
    "print(sorted_series.head(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'5': 746384, '4': 959774, '3': 189949, '2': 50353, '1': 56666, 'Automotive,Replacement Parts,Batteries & Accessories,Battery Accessories,Terminals & Ends': 2, 'Automotive,Replacement Parts,Batteries & Accessories,Battery Accessories,Cables,Switch to Starter': 1}\n"
     ]
    }
   ],
   "source": [
    "rating_count = {}\n",
    "for row in base_labels:\n",
    "    rat = row[\"rating\"]\n",
    "    if rat not in rating_count:\n",
    "        rating_count[rat] = 0\n",
    "    rating_count[rat] += 1\n",
    "\n",
    "print(rating_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
